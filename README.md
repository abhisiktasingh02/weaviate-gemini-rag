```markdown
# ğŸ¤– Weaviateâ€“Gemini RAG Bot (Production Architecture)

![Python](https://img.shields.io/badge/Python-3.10%2B-blue)
![Weaviate](https://img.shields.io/badge/Weaviate-v4-green)
![RAG](https://img.shields.io/badge/RAG-Production--Grade-purple)
![Gemini](https://img.shields.io/badge/Google%20Gemini-2.5%20Flash-orange)

A **production-grade Retrieval-Augmented Generation (RAG)** system that allows you to chat with PDF documents using **Weaviate vector search** and **Google Gemini LLMs**.

This project is designed with **clean architecture, modular components, hallucination guardrails, and multimodal ingestion**, demonstrating how RAG systems are built in real-world AI applications.

---

## ğŸš€ What This Project Demonstrates

âœ” End-to-end RAG pipeline  
âœ” Multimodal ingestion (text, tables, images + OCR)  
âœ” LLM-based query intent parsing  
âœ” Vector search with relevance guardrails  
âœ” Clean separation of retrieval & generation  
âœ” Scalable, extensible architecture  

This is **not a tutorial repo** â€” it reflects **production engineering practices**.

---

## âœ¨ Key Features

### ğŸ“„ Multimodal PDF Ingestion
- Text extraction from PDFs
- Table extraction using `pdfplumber`
- OCR on images using `pytesseract`
- Token-aware chunking with overlap

### ğŸ§  Intelligent Query Parsing
- Uses Gemini to extract:
  - Search intent (definition, explanation, summary, etc.)
  - Semantic search query
  - Modality filters (text / table / image)

### ğŸ” Vector Retrieval with Guardrails
- Semantic search via Weaviate
- Distance-based relevance filtering
- Out-of-scope query rejection to reduce hallucinations

### âœï¸ Grounded Answer Generation
- LLM answers strictly constrained to retrieved context
- Explicit grounding rules to prevent external knowledge leakage

---

## ğŸ—ï¸ System Architecture


User Query
    â†“
LLM Query Parser
    â†“
Vector Retrieval (Weaviate)
    â†“
Relevance Guardrails
    â†“
Context-Grounded Answer Generation (Gemini)
    â†“
Final Response + Source Pages

---

## ğŸ› ï¸ Prerequisites

Before running the project, ensure you have:

- **Docker & Docker Compose**
- **Python 3.10+**
- **Google API Key (Gemini access)**
- **Tesseract OCR**
- **Poppler (PDF utilities)**

---

## ğŸš€ Installation & Setup

### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/abhisiktasingh02/weaviate-gemini-rag.git
cd weaviate-gemini-rag
````

---

### 2ï¸âƒ£ Create `.env` File

```ini
GOOGLE_API_KEY=your_google_api_key
GOOGLE_PROJECT_ID=your_google_project_id
LLM_MODEL=gemini-2.5-flash
```

---

### 3ï¸âƒ£ Start Weaviate (Docker)

```bash
docker-compose up -d
```

Verify:

```bash
docker ps
```

---

### 4ï¸âƒ£ Python Environment Setup

#### Windows (PowerShell)

```powershell
python -m venv .venv
.\.venv\Scripts\activate
```

#### macOS / Linux

```bash
python3 -m venv .venv
source .venv/bin/activate
```

---

### 5ï¸âƒ£ Install Dependencies

```bash
pip install -r requirements.txt
```

> âš ï¸ If OCR fails, ensure **Tesseract** and **Poppler** are installed and added to PATH.

---

## â–¶ï¸ Running the Application

From the **project root**:

```bash
python -m app.main
```

---

### Expected Flow

```text
Enter the path to the PDF document:
Apples_Product_Use_Electricity_Strategy.pdf

âœ… Document ingestion completed.

ğŸ¤– Hi I'm Weaviate Bot. Ask me anything related to the doc! Type 'bye' to quit
```

---

### Example Queries

**In-scope**

```
Summarize Appleâ€™s electricity strategy
```

**Out-of-scope**

```
Who is the CEO of Microsoft?
```

---

## ğŸ“ Project Structure

```text
weaviate-gemini-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Application entry point
â”‚   â”œâ”€â”€ config/                # Environment & prompt configs
â”‚   â”œâ”€â”€ ingestion/             # PDF text, table, image ingestion
â”‚   â”œâ”€â”€ query/                 # LLM-based query parsing & filters
â”‚   â”œâ”€â”€ retrieval/             # Vector search logic
â”‚   â”œâ”€â”€ generation/            # Grounded answer generation
â”‚   â”œâ”€â”€ guardrails/            # Relevance & hallucination checks
â”‚   â”œâ”€â”€ db/                    # Weaviate schema & client setup
â”‚   â””â”€â”€ utils/                 # Shared helpers
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                       # Ignored by git
â””â”€â”€ README.md
```

---

## ğŸ§  Design Decisions

* **Single-pass retrieval** ensures guardrails and generation use identical context
* **Explicit grounding rules** prevent hallucinations
* **Schema idempotency** avoids accidental data loss
* **Modular architecture** supports future extensions (FastAPI, hybrid search, eval)

---

## ğŸ§© Planned Enhancements

* Hybrid search (BM25 + vector)
* RAG evaluation metrics (faithfulness, recall)
* FastAPI service layer
* Multi-PDF memory & chat history
* Observability & tracing

---

## ğŸ¤ Contributing

Contributions, ideas, and reviews are welcome.
Feel free to open an issue or submit a PR.

---

## ğŸ“Œ Author

**Abhisikta Singh**
Software Engineer | AI Systems | RAG & LLM Engineering
[LinkedIn](https://www.linkedin.com/in/abhisiktasingh/)

```